TPS Activity 1
1. What is cache? Why do we need cache?
    Cache = small fast memory unit to temporarily store frequently accessed data/instructions
    Reduces time taken to access data (much faster than main memory/disk)

2. There are generally 2 practical ways to organize a cache: Direct-mapped cache and N-way set associative
cache. In both types of cache, data at a specific address of the main memory (RAM) are mapped to a
pre-defined location in the cache. A “Block” is the basic unit of data being mapped between the main
memory and cache. The size of a block depends on the specification of a cache. Every time data is
transferred between cache and the main memory, it is a block of data being transferred. In this
exercise, we will explore the Direct-mapped cache.

3. In a Direct-mapped cache, the cache is organized as a hash table. Addresses of the main memory are
mapped to the indices of the cache (block numbers) using a modulo operator (%) as the hash function.
As a result, we can divide a memory address into 3 fields: tag, index, offset.

4. Offset bits tell us how many bytes of data are in a block. These bits are the
right-most bits of the memory address. You can consider this as the number of columns of data in a cache. With a specific
value of the offset bits from an address, we know which column of a block we are trying to access.

Given the block size of a cache is 16B (bytes), how many bits do we need for offset? What is the
number of bits in offset as a function of block size? Is it practical to have a cache of block size = 1 byte?
    2^4 = 16, 4 bits for offset
    Number of bots for offset = log2(blockSize)


5. Index bits tell us how many blocks there are in a cache. These bits are
the next right-most bits of the memory address after the offset bits. You can consider this as the number of blocks (rows) of data
in a cache. With a specific value of the index bits from an address, we know which block (row) we are
trying to access. 
Given there are 64 blocks in a cache, how many index bits do we need? What is the
number of bits in index as a function of number of blocks?
    2^6 = 64, 6 bits for index
    Number of index bits = log2(numberOfBlocks)

6. Once you know the number of blocks and the block size of a cache, do you know the total size of the
cache? How?
    Yes
    Total size = Block size * Number of blocks
    (Cache with 64 block * block size 16B = total size 1024B)

7. Since the size of cache is always smaller than the size of the main memory, the sum of bits of the offset
and index of a cache will be less than the number of bits in an address of the main memory. What do we
do to the left-over bits from the address? Why are they important?
    Leftover bits = tag bits
    Identifies which block of data = stored in particular cache location

8. Given a memory address of 20 bits (during Intel 8086 era), 128B of direct-mapped cache, and 8B
block size, answer the following questions:

a. How big is this main memory?
    2^20 bytes = 1MB

b. How many offset bits?
    log2(8) = 3 bits

c. How many blocks are there in the cache?
    numberOfBlocks = cacheSize / blockSize
    128B / 8B = 16 blocks

d. How many index bits?
    log2(16) = 4 bits

e. How many tag bits?
    totalAddressBits - (offserBits + indexBits) 
    20 - (3 + 4) = 13 bits

f. Draw the layout of the cache: including tags, valid bits, dirty bits, and data blocks.
    [tag (13 bits)][validBit (1 bits) ][dirtyBit (1 bits) ][dataBlock (8 bits)]

g. What is the number of bits per row of the cache (number of bits being used in a row: tag, valid bit,
dirty bits, and data block)?
    numbersOfBitsPerRow = tagBits + validBit + dirtyBit + dataBlock
    13 + 1 + 1 + 8 = 23bits

TPS Activity 2

1. What is the disadvantage of a Direct-mapped cache? What kind of cache miss will it introduce?
    Disadvantage = conflicts where multiple memory blocks map to the same cache location
    Cache thrashing = compulsory cache misses

2. To overcome this problem, we can allow multiple blocks of data to occupy the same
set of a cache.
Note that we use “set” here instead of index of cache. In this organization, we group N blocks (rows) of
cache into a set and allow more than one block of data to stay within a set. The layout of the cache
remains the same as its direct-mapped version, but the difference is that every N blocks are now being
grouped into a set.

3. The memory address is still partitioned into the same 3 fields, but the index bits now refer to the set
number. Given a cache with 1024 blocks and the associativity is 4 (4 blocks per set), how many index
bits do we need? What is the number of bits in index as a function of number of blocks and
associativity?
    Number of sets = 1024/4 = 256 sets
    log2(256) = 8 bits for index

4. Given a memory address of 20 bits (during Intel 8086 era), 128B of 2-way cache, and 8B block size,
answer the following questions:

a. How big is this main memory?
    2^20 bytes = 1MB

b. How many offset bits?
    log2(8) = 3bits

c. How many blocks are there in the cache?
    cacheSize / blockSize 
    128B / 8B = 16 blocks

d. How many sets are there in the cache?
    numberOfBlocks / associativity
    16 / 2 = 8 sets

e. How many index bits?
    log2(8) = 3 bits

f. How many tag bits?
    totalAddressBits - (offsetBits + indexBits)
    20 - (3 + 3) = 14 bits

g. Draw the layout of the cache: including tags, valid bits, dirty bits, and data blocks. Indicate the sets
with a different color (or a thicker) boarder.
    Set 1:                                                                  Set 2:
    |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (8)]|            |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (1)]|     
    |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (8)]|            |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (1)]|

    Set 3:                                                                  Set 4:
    |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (8)]|            |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (1)]|     
    |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (8)]|            |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (1)]|

    Set 5:                                                                  Set 6:
    |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (8)]|            |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (1)]|     
    |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (8)]|            |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (1)]|

    Set 7:                                                                  Set 8:
    |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (8)]|            |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (1)]|     
    |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (8)]|            |[tag (14)] [validBits (1)] [dirtyBits (1)] [dataBlock (1)]|

h. What is the number of bits per row of the cache (number of bits being used in a row: tag, valid bit,
dirty bits, and data block)?
    numberOfBitsPerRow = tagBits + validBit + dirtyBit + dataBlock
    14 + 1 + 1 + 8 = 24 bits